
---
title: "Practical Machine Learning Assignment"
author: "m123"
date: "March 21, 2015"
output: html_document
---
Github repo with RMarkdown: 

INTRODUCTION:
------------
This document represents the results from data using devices such as Jawbone Up, Nike FuelBand, and Fitbit. The goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, quantify how well they do the exercises and predict the manner in which they did it. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

Create a report to describe: 
1. how the model was built
2. how cross validation was used
3. what the expected out of sample error is 
4. why the choices were made. 

Use 20 different test cases.
The following packages used include caret, randomForest, Hmisc, foreach and doParallel.
```{r}
# Load libraries and set seed
library(caret)
library(randomForest)
library(Hmisc)
library(doParallel)
library(rpart)
library(rpart.plot)
library(corrplot)
library(ggplot2)
library(lattice)
library(knitr)
```

Load the file data
```{r}
Url1 <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
Url2 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train <- "./data/pml-training.csv"
test  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(train)) {
  download.file(Url1, destfile=train, method="curl")
}
if (!file.exists(test)) {
  download.file(Url2, destfile=test, method="curl")
}      
```

Organize the csv files into proper data frames to read
```{r, echo=TRUE}
train.data <- read.csv("./data/pml-training.csv", row.names=1, na.strings = " ")
test.data <- read.csv("./data/pml-testing.csv", row.names=1,  na.strings = "NA")
dim(train.data)
dim(test.data)
```
Training data has 19622 observations with 159 variables. Testing data has 20 observations with 159 variables. 
Hence, start cleaning the data by removing 60% of NA values and remove columns with missing values. Identify the classe variable in the training set.

Clean the Data by removing NA missing values
```{r}
train.data <- train.data[, colSums(is.na(train.data)) == 0]
test.data <- test.data[, colSums(is.na(test.data)) == 0]
```
Upon reviewing the data, we also remove columns that do not reveal much for accelerometer data and create the classe variable function.
```{r}
# Remove near zero covariates that hamper prediction
zero.co <- nearZeroVar(train.data, saveMetrics = TRUE)
train.data <- train.data[, !zero.co$nzv]
# Create Class function
classe <- train.data$classe
# delete unnecessary training data, create new set training data
train.delete <- c("raw_timestamp.part_1", "raw_timestamp_part_2", "user_name", "cvtd_timestamp", "new_window", "num_window")
train.data2 <- train.data[, !(names(train.data) %in% train.delete)]
## delete unnecessary test data, create new set test data
test.delete <- c("problem_id", "raw_timestamp.part_1", "raw_timestamp_part_2", "user_name", "cvtd_timestamp", "new_window", "num_window")
test.data2 <- test.data[, !(names(test.data) %in% test.delete)]
dim(train.data2)
dim(test.data2)
```
Train data2 has 19622 observations and 54 variables. Test data2 has 20 observations and 53 variables.
Begin process for Cross Validation by doing a data split of train data 70% and validation data of 30%
```{r}
inTrain <- createDataPartition(y=train.data2$classe, p= 0.70, list=FALSE)
train.data3 <- train.data2[inTrain, ]
test.data3 <- train.data2[-inTrain, ]
dim(train.data3)
dim(test.data3)
```
Train data3 has 13737 observations and 54 variables. Test data has 5885 observations and 54 variables.

Random Forest Modeling
Conduct the predictive modeling with 5 fold cross-validation.

```{r}
set.seed(2345)
fit.Rf <- trainControl(method = "cv", 5)
fit.Rf2 <- train(classe ~ ., data=train.data3, method="rf", trControl=fit.Rf, importance = TRUE, ntree=100)
fit.Rf2
```
Validate the data set and out-of-sample error.
```{r}
predict.Rf <- predict(fit.Rf2, test.data3)
confusionMatrix(test.data3$classe, predict.Rf)
out.error <- 1 - as.numeric(confusionMatrix(test.data3$classe, predict.Rf)$overall[1])
out.error
```
Accuracy of Model is good with a 99.22% and an out of sample error of 85% which is decently low, with 5 fold cross validation.
Going back to the initial data set testing we do a prediction:
```{r}
data.final <- predict(fit.Rf2, newdata = (test.data2))
data.final
```
Plot Figures:
```{r}
## Model Variables
model <- varImp(fit.Rf2)$importance
varImpPlot(fit.Rf2$finalModel, main = "Predictors", sort = TRUE, pch = 21, col = 1, cex =1)
## Decision Tree
tree <- rpart(classe ~ ., data= train.data3, method = "class")
predictiontree <- predict(tree, test, type="class")
rpart.plot(tree, under = TRUE)
```
Files to Submit Assignment
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./answers/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)
```
Sources: 
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3V12rBpJB

End Notes: Codes were produced on RStudio version 0.98.994 with a Mac OS 10.9.4 
